---
title: "Probability distributions"
format: html
editor: visual
---

# 14.1 Packages we need

```{r}
library(tidyverse)
library(igraph)
```

# 14.2 Random variables and probability distributions

A **random variable** assigns a numerical quantity to every possible outcome of a random phenomenon and can be:

-   discrete if it takes either a finite number or an infinite sequence of possible values

-   continuous if it takes any value in some interval on the real numbers

Example of the blood type:

-   X = 1 for blood type A

-   X = 2 for blood type B

-   X = 3 for blood type AB

-   X = 4 for blood type O

The **probability distribution** describes the probability of different possible values of random variable X.

Probability distributions are often presented using probability tables or graphs:

|                |      |      |      |      |
|----------------|------|------|------|------|
| **Blood type** | A    | B    | AB   | O    |
| **X**          | 1    | 2    | 3    | 4    |
| **P(X)**       | 0.41 | 0.10 | 0.04 | 0.45 |

Blood types matching for a safe transfusion:

```{r}
# data in a form of a matrix
x <- c(1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1)
nodes_names <- c("O", "A", "B", "AB")
adjm <- matrix(x, 4, dimnames = list(nodes_names, nodes_names))

set.seed(124)
# build the graph object
network <- graph_from_adjacency_matrix(adjm)

# plot it
plot(network, vertex.size= 32, vertex.color = "red")
```

What is the probability that a random selected person from the population can donate blood to someone with type B blood?

$$
P(blood\ type\ B\ OR\ blood\ type\ O)=P(X=2)+P(X=4)=0.10+0.45=0.55
$$

Degrees of freedom (i.e., the number of parameters that are free to vary) are intrinsic to probability distributions, influencing their shapes, properties, and applications and statistical analysis. For instance, in the chi-square, t, and F distributions, degrees of freedom determine their characteristics.

# 14.3 Discrete probability distributions

The probability distribution of a discrete random variable X is defined by the **probability mass function (pmf)** as:

$$
P(X=x)=P(x)
$$

where

$P(X=x)$ is the probability that the random variable X takes value x and

$P(x)$ is the probability of the specific outcome x occuring

The pmf has two properties:

-   $P(x) \ge 0$

-   $\sum_xP(x)=1$

The **cumulative distribution function (cdf)** gives the probability that the random variable X is less than or equal to x and is usually denoted as F(x):

$$
F(x)=P(X \le x) = \sum_{x_i \le x}P(x_i)
$$

When dealing with a random variable, it is common to calculate three important summary statistics: the expected value, variance and standard variation.

-   Expected value, denoted $E(X)$ or $\mu$ is defined as the weighted average of the values that X can take on, with each possible value being weighted by its respective probability, $P(x)$

$$
\mu=E(X)=\sum_i x_i.P(x_i)
$$

-   Variance, denoted $\sigma^2$ is a measure of the variability of the X

$$
\sigma^2=Var(X)=E[X-E(X)]^2=E[(X-\mu)^2]=\sum_i (x_i-\mu)^2P(x_i)
$$

There is an easier form of this formula:

$$
\sigma^2=Var(X)=E(X^2)-E(X)^2=\sum_i x_i^2P(x_i)-\mu^2
$$

-   Standard deviation: square root of the variance

$$
\sigma=\sqrt{Var(X)}=\sqrt{\sigma^2}
$$

## 14.3.1 Bernouilli distribution

A random experiment with two possible outcomes, generally referred to as success (x=1) and failure (x=0), is called a **Bernouilli trial**.

Let X be a binary random variable of a Bernouilli trial which takes the value 1 (success) with probability p and 0 (failure) with probability (1-p).

The distribution of the X variable is called Bernouilli distribution with parameter $p$, denoted as $X \sim Bernouilli(p)$, where $0 \le p \le 1$

-   Probability mass function pmf:

    $$
    P(X=x)=\left\{{1-p, \text{ for x = 0}\atop p, \text{ for x = 1}}\right.
    $$

or

$$
P(X=x)=p^x(1-p)^{1-x} for\ x\in\{0,1\}
$$

\$\$

\$\$

-   Cumulative distribution function cdf of X:

$$
F(x) = P(X \le x)= {\begin{cases}0,&for\ x <0\\1-p,&for\ 0\leq x < 1\\1,&for\ x \geq 1 \end{cases}}
$$

The expected value of random variable X, with Bernouilli(p) distribution is:

$$
\mu=E(X)=p
$$

The variance is:

$$
\sigma^2=Var(X)=p(1-p)
$$

And the standard deviation is:

$$
\sigma=\sqrt{Var(X)}=\sqrt{p(1-p)}
$$

Let X be a random variable representing the result of a surgical procedure, where X = 1 if the surgery was successful and X = 0 if it was unsuccessful. Suppose that the probability of success if 0.7; then X follows a Bernouilli distribution with parameter $p=0.7$:

$$
X\sim Bernouilli(0.7)
$$

-   The pmf for this distribution is:

$$
P(X=x)={\begin{cases}0.3,&for\ x=0\\0.7,&for\ x=1\end{cases}}
$$

|          |     |     |
|----------|-----|-----|
| **X**    | 0   | 1   |
| **P(X)** | 0.3 | 0.7 |

```{r}
# Create a data frame
x <- as.factor(c(0, 1))
y <- c(0.3, 0.7)
dat1 <- data.frame(x, y)
 
# Plot
ggplot(dat1, aes(x = x, y = y)) +
  geom_segment(aes(x = x, xend=x, y=0, yend = y), color = "black") +
  geom_point(color="deeppink", size = 4) +
  theme_classic(base_size = 14) +
  labs(title = "pmf Bernoulli(0.7)",
       x = "X", y = "Probability") +
  theme(axis.text = element_text(size = 14))
```

-   The cdf of this distribution is:

$$
F(x) = P(X \le x)={\begin{cases}0,&for\ x <0\\0.3,&for\ 0\leq x < 1\\1,&for\ x \geq 1 \end{cases}}
$$

```{r}
# Create a data frame
dat2 <- data.frame(x = -1:2, 
                   y =  pbinom(-1:2, size = 1, prob = 0.7))
# Step line plot
ggplot(dat2, aes(x=x, y=y)) +
  geom_step() +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_classic(base_size = 14) +
  labs(title = "cdf Bernoulli(0.7)", 
       x = "X", y = "F(x)") +
  theme(axis.text = element_text(size = 14))
```

-   The mean is $\mu=p=0.7$ and the variance is $\sigma^2=p(1-p)=0.7.(1-0.7)=0.7 * 0.3=0.21$

## 14.3.2 Binomial distribution

1.  There is a fixed number of *n* repeated Bernoulli trials
2.  The *n* trials are all independent. That is, knowing the result of one trial does not change the probability we assign to other trials
3.  Both probability of success, *p*, and probability of failure, *1-p*, are constant throughout the trials

Let X be a random variable that indicates the number of successes in –independent Bernouilli trials. If random variable X satisfies the binomial setting, it follows the binomial distribution with parameters *n* and *p*, denoted as $X \sim Binomial(n,p)$ where *n* is the Bernouilli trial parameter (a positive integer) and *p* the Bernouilli probability parameter ($0\le p \lt 1$).

-   The probability mass function (pmf) of X is given by :

$$ P(X=x) = {{n}\choose{x}} \cdot p^x \cdot (1-p)^{n-x}$$ {#eq-binom0}

where x = 0, 1, ... , n and $\binom{n}{x} = \frac{n!}{x!(n-x)!}$

Note that: $n! = 1\cdot 2 \cdot 3\cdot \ldots \cdot (n-2)\cdot (n-1)\cdot n$

-   The cumulative distribution function (cdf) of X is given by :

$$F(x) = P(X \le x)=  {\begin{cases}0,&for\ x <0\\\sum_{k=0}^{x}{\left( \begin{array}{c} n \\ k \end{array}
 \right) p^{k}(1 - p)^{n-k}},&for\ 0\leq x < n\\1,&for\ x \geq n \end{cases}}$$

The mean of random variable X with Binomial(n,p) distribution is :

$$
\mu = np
$$

The variance is:

$$
\sigma^2=np(1-p)
$$

And the standard deviation is

$$
\sigma = \sqrt{np(1-p)}
$$

Let the random variable X be the number of successful surgical procedures and suppose that a new surgery method is successful 70% of the time (p=0.7). If the results of 10 surgeries are randomly sampled, and X follows a Binomial distribution $X \sim Binomial(10, 0.7)$, find the main characteristics of this distribution.

-   The pmf for this distribution is:

$$ P(X=x) = {{10}\choose{x}} \cdot 0.7^x \cdot (1-0.7)^{10-x}$$

The pmf of Binomial(10, 0.7) distribution specifies the probability of 0 through 10 successful surgical procedures.

|          |     |        |        |       |     |       |       |       |
|----------|-----|--------|--------|-------|-----|-------|-------|-------|
| **X**    | 0   | 1      | 2      | 3     | ... | 8     | 9     | 10    |
| **P(X)** | 0   | 0.0001 | 0.0014 | 0.009 | ... | 0.233 | 0.121 | 0.028 |

Compute the above probabilities using the `dbinom()` function :

```{r}
dbinom(0:10, size = 10, prob = 0.7)
```

Plot the pmf:

```{r}
# Create a data frame
dat3 <- data.frame(x = 0:10, 
                   y = dbinom(0:10, size = 10, prob = 0.7))

# Plot
ggplot(dat3, aes(x = x, y = y)) +
  geom_segment(aes(x = x, xend=x, y=0, yend = y), color = "black") +
  geom_point(color="deeppink", size = 4) +
  theme_classic(base_size = 14) +
  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, 1)) +
  labs(title = "pmf Binomial(10, 0.7)",
       x = "X", y = "Probability") +
  theme(axis.text = element_text(size = 14))
```

-   The cdf for this distribution is:

$$F(x) = P(X \le x)={\begin{cases}0,&for\ x <0\\\sum_{k=0}^{x}{\left( \begin{array}{c} 10 \\ k \end{array}
 \right) 0.7^{k}(1 - 0.7)^{10-k}},&for\ 0\leq x < 10\\1,&for\ x \geq 10 \end{cases}}$$

Calculate the cumulative probabilities for all the possible outcomes using the `pbinom()` function:

```{r}
# find the cumulative probabilities
pbinom(0:10, size = 10, prob = 0.7)
```

```{r}
# Create a data frame
dat4 <- data.frame(x = 0:10, 
                   y = pbinom(0:10, size = 10, prob = 0.7))

# Step line plot
ggplot(dat4, aes(x=x, y=y)) +
  geom_step() +
  theme_classic(base_size = 14) +
  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, 1)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  labs(title = "cdf Binomial(10, 0.7)",
       x = "X", y = "F(x)") +
  theme(axis.text = element_text(size = 14))
```

The mean is $\mu=np=10*0.7=7$ successful surgeries and the variance is $\sigma^2=np(1-p)=10*0.7*0.3=2.1$.

Let's calculate the probability of having more than 8 successful surgical procedures out of a total of 10. Therefore, we want to calculate the probability $P(X>8)$:

$$ P(X > 8)= P(X = 9) + P(X = 10) = {{10}\choose{9}} \cdot 0.7^9 \cdot 0.3^1 + {{10}\choose{10}} \cdot 0.7^{10} \cdot 0.3^0 \Rightarrow $$

$$ P(X > 8)= 10 \cdot 0.04035 \cdot 0.3 + 1 \cdot 0.02824 = 0.12105 + 0.02825 = 0.1493$$

```{r}
p9 <- dbinom(9, size=10, prob=0.7)
p9
```

```{r}
p10 <- dbinom(10, size = 10, prob = 0.7)
p10
```

```{r}
p9 + p10
```

Another way to find the above probability is to calculate $1-P(X \le 8)$:

```{r}
1 - pbinom(8, size = 10, prob = 0.7)
```

## 14.3.3 Poisson distribution

The Poisson setting:

1.  The events (occurrences) are counted within a fixed interval of time or space. The interval should be well-defined and consistent.
2.  Each event is assumed to be independent of the others. The occurrence of the event does not affect the probability of another event happening.
3.  The probability of an event occurring remains consistent throughout the interval.

Let X be a random variable that indicates the number of events (occurrences) that happen within a fixed interval of time or space. If $λ$ represents the average rate of events (occurrences) in this interval or space, the X has a Poisson distribution that is specified by the parameter $λ$, denoted as $X ∼ Poisson(λ)$, where $λ$ is a positive real number ($λ >0$).

-   The probability mass function (pmf) of X is given by:

$$ P(X=x)={\frac {\lambda ^{x}e^{-\lambda }}{x!}} $$ {#eq-poisson1}

where x = 0, 1, ... +∞, λ \> 0.

-   The cumulative distribution function (cdf) of X is given by:

$$F(x) = P(X \le x)=  {\begin{cases}0,&for\ x <0\\\sum_{k=0}^{x}{ \begin{array}{c} 
\frac {\lambda ^{k}e^{-\lambda }}{k!}
\end{array}},&for\ x\geq 0 \end{cases}}$$ {#eq-poisson0.1}

The mean and variance of a random variable that follows the Poisson(λ) distribution are the same and equal to λ:

-   μ = λ
-   $σ^2$ = λ

Let X be a random variable of the number of successful heart transplant surgeries per week in a specialized clinic center. We assume that the average rate of successful surgeries per week is 2.5 ($\lambda=2.5$) and X follows a Poisson distribution :

$X \sim Poisson(2.5)$

-   The probability mass function (pmf) of X is :

    $$ P(X=x)={\frac {2.5 ^{x}e^{-2.5 }}{x!}} $$

The resulting probability table is :

|          |       |       |       |       |       |       |       |      |       |     |
|----------|-------|-------|-------|-------|-------|-------|-------|------|-------|-----|
| **X**    | 0     | 1     | 2     | 3     | 4     | 5     | 6     | 7    | 8     | ... |
| **P(X)** | 0.082 | 0.205 | 0.257 | 0.214 | 0.134 | 0.067 | 0.028 | 0.01 | 0.003 | ... |

We can compute the above probabilities using the `dpois()` function :

```{r}
dpois(0:8, lambda = 2.5)
```

We can plot the pmf :

```{r}
# Create a data frame
dat5 <- data.frame(x = 0:8, 
                   y = dpois(0:8, lambda = 2.5))

# Plot
ggplot(dat5, aes(x = x, y = y)) +
  geom_segment(aes(x = x, xend=x, y=0, yend = y), color = "black") +
  geom_point(color="deeppink", size = 4) +
  theme_classic(base_size = 14) +
  scale_x_continuous(limits = c(0, 8), breaks = seq(0, 8, 1)) +
  labs(title = "pmf Poisson(2.5)",
       x = "X", y = "Probability") +
  theme(axis.text = element_text(size = 14))
```

We can compute the cumulative probabilities using the `ppois()` function :

```{r}
ppois(0:8, lambda = 2.5)
```

To plot the cdf for this distribution :

```{r}
# Create a data frame
dat6 <- data.frame(x = 0:8, 
                   y = ppois(0:8, lambda = 2.5))

# Step line plot
ggplot(dat6, aes(x=x, y=y)) +
  geom_step() +
  theme_classic(base_size = 14) +
  scale_x_continuous(limits = c(0, 8), breaks = seq(0, 8, 1)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  labs(title = "cdf Poisson(2.5)",
       x = "X", y = "F(x)") +
  theme(axis.text = element_text(size = 14))
```

To calculate the probability of up to four successful hear transplant surgeries per week :

```{r}
ppois(4, lambda = 2.5)
```

# 14.4 Probability distributions for continuous outcomes

Unlike discrete random variables, which have a probability mass function (pmf) that assigns probabilities to individual values, **continuous random variables** have a **probability density function** (pdf), denoted as f(x), which satisfies the following properties:

-   $f(x) \geq 0$
-   $\int_{-\infty}^{+\infty} f(x) \, dx = 1$

In this case, we are interested in the probability that the value of the random variable X is within a specific interval from $x_1$ to $x_2$, denoted as $P(x_1 ≤ X ≤ x_2)$.

$$ P(x_1\leq X \leq x_2)=\int_{x_1}^{x_2}f(x)dx $$

The graphical representation of the probability density function referred to as a density plot. In this plot, the x-axis represents the possible values of the variable X, while the y-axis represents the probability density.

```{r}
# Create a data frame
set.seed(1234)
df <- data.frame(w = round(c(rnorm(200, mean=175, sd=8),
                             rnorm(200, mean=155, sd=8)))
                 )

df1 <- with(density(df$w), data.frame(x, y))

ggplot(df1, mapping = aes(x = x, y = y)) +
  geom_line()+
  geom_area(mapping = aes(x = ifelse(x > 170 & x < 175 , x, 0)), fill = "#0073CF") +
  xlim(120, 210) +
  labs(y = "f(x)") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)
```

Additionally, from the pdf we can find the **cumulative probability** by calculating the area from -∞ to a specific value $x_0$.

The **cumulative distribution function** (cdf) gives the probability that the random variable X is less than or equal to $x_0$ and is usually denoted as:

$$ F(x_o) = P(X\leq x_o)=\int_{- \infty }^{x_o}f(x)dx $$

where $-\infty \leq x_o \leq + \infty$

```{r}
ggplot(df1, mapping = aes(x = x, y = y)) +
  geom_line()+
  geom_area(mapping = aes(x = ifelse(x > -Inf & x < 173 , x, 0)), fill = "#0073CF") +
  xlim(120, 210) +
  labs(y = "f(x)") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)
```

The probability of a certain point value in X is zero, and the area under the probability density curve of the interval (−∞, +∞) should be 1.

The expected value or mean, denoted as **E(X)** or **μ**, is calculated by integrating over the entire range of possible values:

$\mu =E(X) = \int_{-\infty}^{+\infty} x \cdot f(x) \, dx$

We can also calculate the variance of the variable X.

$\sigma^2=\text{Var}(X) = E[(X - \mu)^2] = \int_{-\infty}^{+\infty} (x - \mu)^2 \cdot f(x) \, dx$

The standard deviation is often preferred over the variance because it is in the same units as the random variable.

$\sigma=\sqrt{\text{Var(X)}}=\sqrt{\sigma^2}$

## 14.4.1 Uniform distribution

The simplest continuous probability distribution is the uniform distribution. Let X be a continuous random variable that follows the uniform distribution with parameters the minimum value $a$ and the maximum value $b$ ($a<b$), $X \sim Uniform (a,b)$

-   The probability density function (pdf) of X is given by:

$$f(x) = \begin{cases}
\frac{1}{b - a} & \text{for } a \leq x \leq b \\
0 & \text{otherwise}
\end{cases}$$

-   The cumulative distribution function (cdf) of X is:

$$F(x) = \begin{cases}
0 & \text{for } x < a \\
\frac{x - a}{b - a} & \text{for } a \leq x \leq b \\
1 & \text{for } x > b
\end{cases} $$

The mean of X is given by:

$$\mu = \frac{a + b}{2}$$

The variance of the X is given by: $$\sigma^2 = \frac{(b - a)^2}{12}$$

The uniform distribution, with a=0 and b=1, is highly useful as a random number generator.

Let X be a random variable that follows the uniform distribution. Find the main characteristics of this distribution.

Then utilize this distribution to randomize 100 individuals between treatments A and B in a clinical trial.

-   The pdf for this distribution is:

$$f(x) = \begin{cases}
1 & \text{for } 0 \leq x \leq 1 \\
0 & \text{otherwise}
\end{cases}$$

```{r}
# Define the range of x values (including values outside the range)
x_values <- seq(-0.5, 1.5, by = 0.01)

# Calculate the PDF values for the uniform distribution
pdf_values <- dunif(x_values, min = 0, max = 1)

# Create a data frame for the PDF plot
pdf_data <- data.frame(x = x_values, PDF = pdf_values)

# Plot the PDF
ggplot(pdf_data, aes(x = x, y = PDF)) +
  geom_line() +
  xlim(-0.5, 1.5) +
  labs(title = "pdf Uniform(0, 1)",
       x = "X", y = "P(x)") +
  theme(axis.text = element_text(size = 14))
```

-   The cdf for this distribution is:

$$F(x) = \begin{cases}
0 & \text{for } x < 0 \\
x & \text{for } 0 \leq x \leq 1 \\
1 & \text{for } x > 1
\end{cases} $$

```{r}
# Calculate the CDF values for the uniform distribution
cdf_values <- punif(x_values, min = 0, max = 1)

# Create a data frame for the CDF plot
cdf_data <- data.frame(x = x_values, CDF = cdf_values)

# Plot the CDF
ggplot(cdf_data, aes(x = x, y = CDF)) +
  geom_line() +
  xlim(-0.5, 1.5) +
    labs(title = "cdf Uniform(0, 1)",
         x = "X", y = "F(x)") +
  theme(axis.text = element_text(size = 14))
```

The mean and variance of a random variable that follows the Uniform(0, 1) distribution are:

-   $μ = \frac{0 + 1}{2} = \frac{1}{2}$
-   $σ^2 = \frac{(1 - 0)^2}{12} = \frac{1}{12}$

Next, we use Uniform(0,1) to randomize individuals between treatments A and B in a clinical trial:

```{r}
# Set seed for reproducibility
set.seed(235)

# Define the sample size of the clinical trial
N <- 100

# Create a data frame to store the information
data <- data.frame(id = paste("id", 1:N, sep = ""), trt = NA)

# Simulate 100 uniform random variables from (0-1)
x <- runif(N)
# Display the first 10 values
x[1:10]
```

```{r}
# Make treatment assignments, if x < 0.5 treatment A else B
data$trt <- ifelse(x < 0.5, "A", "B")

# Display the first few rows of the data frame
head(data, 10)
```

```{r}
# Display the counts and proportions of each treatment
table(data$trt)
```

```{r}
prop.table(table(data$trt))
```

## 14.4.2 Normal distribution

A normal distribution, also known as a Gaussian distribution, is a fundamental concept in statistics and probability theory and is defined by two parameters : the mean ($\mu$) and the standard deviation ($\sigma$).

-   The probability density function (pdf) of $X ∼ Normal(μ, σ^2)$ is given by:

$$ f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}} $$

where $\pi \approx 3.14$ and $e \approx 2.718$.

-   The cumulative distribution function (cdf) of X sums from negative infinity up to the value of $x_o$, which is $(-∞, x_o]$ in interval notation:

$$ F(x_o) = P(X\leq x_o)={\frac {1}{\sigma {\sqrt {2\pi }}}} \int_{- \infty }^{x_o}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}}dx $$

where $-\infty \leq x_o \leq + \infty$

Let's say that in a population the random variable of height, X, for adult people approximates a normal distribution with a mean $\mu$ = 170cm and a standard deviation $\sigma$ = 10 cm.

The pdf for this distribution is shown below:

```{r}
ggplot() +
  geom_function(fun = dnorm, args = list(mean = 170, sd = 10), 
                color= "gray20", linewidth = 1) +
  xlim(135, 205) +
  labs(x = "X", y = "Probabiblity Density, f(x)",
       title = "The Normal Distribution, N~(170, 10^2)") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)
```

The normal cumulative distribution function (cdf) is shown below.

Note that continuous variables generate a smooth curve, while discrete variables produce a stepped line plot.

```{r}
# Create a data frame
dat7 <- data.frame(x = seq(135, 205, by = 0.1), 
                   y = pnorm(seq(135, 205, by = 0.1), mean=170, sd=10))
# Plot
ggplot(dat7, aes(x=x, y=y)) +
  geom_step() +
  labs(x = "X", y = "Cumulative Probabiblity, F(x)") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)
```

Let's assume that we want to calculate the area under the curve between 160 cm and 180 cm, that is:

$$ P(160\leq X \leq 180)=\int_{160}^{180}f(x)dx $$

```{r}
# Create a data frame
df2 <- data.frame(x = seq(135, 205, by = 0.1),
                   y = dnorm(seq(135, 205, by = 0.1), mean=170, sd=10))

# Create the plot
ggplot(df2, aes(x = x, y = y)) +
  geom_function(fun = dnorm, args = list(mean = 170, sd = 10), 
                color= "gray20", linewidth = 1) +
  geom_area(mapping = aes(x = ifelse(x > 160 & x < 180, x, 0)), fill = "#0073CF", alpha = 0.4) +  # Area under the curve
  xlim(135, 205) +
  labs(x ="x", y = "Probability density",
       title = "Area Under the Normal Distribution Curve") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)
```

Using the properties of integrals we have:

$$ \int_{-\infty}^{180}f(x)dx = \int_{-\infty}^{160}f(x)dx + \int_{160}^{180}f(x)dx $$ $$ \Leftrightarrow \int_{160}^{180}f(x)dx = \int_{-\infty}^{180}f(x)dx - \int_{-\infty}^{160}f(x)dx $$ $$ \Leftrightarrow P(160\leq X \leq 180) = P(X \leq 180)- P(X \leq 160) $$

-   Lets calculate the $P(X \leq 180)$:

$$ P(X \leq 180)=\int_{-\infty}^{180}f(x)dx $$

```{r}
# Create the plot
ggplot(df2, aes(x = x, y = y)) +
  geom_function(fun = dnorm, args = list(mean = 170, sd = 10), 
                color= "gray20", linewidth = 1) +
  geom_area(mapping = aes(x = ifelse(x > 135 & x < 180, x, 0)), fill = "#0073CF", alpha = 0.4) +  # Area under the curve
  xlim(135, 200) +
  labs(x = "X", y = "Probability density",
       title = "Area Under the Normal Distribution Curve") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)pnorm(180, mean = 170, sd = 10)
```

```{r}
pnorm(180, mean = 170, sd = 10)
```

-   Similarly, we can calculate the $P(X \leq 160)$:

$$ P(X \leq 160)=\int_{-\infty}^{160}f(x)dx $$

```{r}
# Create the plot
ggplot(df2, aes(x = x, y = y)) +
  geom_function(fun = dnorm, args = list(mean = 170, sd = 10), 
                color= "gray20", linewidth = 1) +
  geom_area(mapping = aes(x = ifelse(x > 135 & x < 160, x, 0)), fill = "#0073CF", alpha = 0.3) +  # Area under the curve
  xlim(135, 200) +
  labs(x = "X", y = "Probability density",
       title = "Area Under the Normal Distribution Curve") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)
```

```{r}
pnorm(160, mean = 170, sd = 10)
```

Finally, we subtract the two values:

```{r}
pnorm(180, mean = 170, sd = 10) - pnorm(160, mean = 170, sd = 10)
```

## 14.4.3 Standard Normal distribution

If X is a random variable with a normal distribution having a mean of $\mu$ and a standard deviation of $\sigma$, then the standardized Normal deviate can be expressed as:

$$ z= \frac{x-\mu}{\sigma} $$ {#eq-z}

The z (often called z-score) is a random variable that has a Standard Normal distribution, also called a z-distribution, i.e. a special normal distribution where $\mu=0$ and $\sigma^2=1$. In this case, the gaussian equation is transformed as follows:

$$ f(z)={\frac {1}{{\sqrt {2\pi }}}}e^{-{\frac {1}{2}}z^2} $$

```{r}
ggplot() +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +
  scale_x_continuous(limits = c(-3, 3), breaks = seq(-3, 3, 1)) +
  labs(x = "Z", y = "Probabiblity density, f(z)",
       title = "The Standard Normal Distribution, N~(0, 1^2)") +
  scale_y_continuous(expand = c(0,0.005)) +
  theme_classic(base_size = 14)
```

Let's assume that the diastolic blood pressure distribution among men has a normal distribution with mean 80 mmHg and standard deviation 15 mmHg. If an individual's diastolic blood pressure is recorded as 110 mmHg, how many standard deviations differs from the population mean?

The z-score equation is:

$z = \frac{(110 – 80)}{15} = 2$

This person has a diastolic blood pressure that is 2 standard deviations above the population mean.

To find the area under the curve between two z-scores, $z_1$ and $z_2$, we have to integrate the pdf equation as follows:

$$ P(z_1\leq Z\leq z_2)={\frac {1}{{\sqrt {2\pi }}}}\int_{z_1}^{z_2}e^{-{\frac {1}{2}}z^2}dz $$

Let's calculate the area under the curve for $z_1=0$ and $z_2=2$:

```{r}
# Create a data frame
df3 <- data.frame(x = seq(-3, 3, by = 0.01),
                   y = dnorm(seq(-3, 3, by = 0.01), mean=0, sd=1))

ggplot(df3, aes(x = x, y = y)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +
  geom_area(mapping = aes(x = ifelse(x > 0 & x < 2, x, 0)), fill = "#0073CF", alpha = 0.3) +  # Area under the curve
  scale_x_continuous(limits = c(-3, 3), breaks = seq(-3, 3, 1)) +
  labs(x = "Z", y = "Probabiblity density, f(z)",
       title = "The Standard Normal Distribution, N~(0, 1^2)") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)
```

In R, we can easily calculate the above area using the cdf of the normal distribution:

$$P(0\leq Z\leq 2) = P(Z\leq 2) - P(Z\leq 0)$$

```{r}
pnorm(2, mean = 0, sd = 1) - pnorm(0, mean = 0, sd = 1)
```

## 14.4.4 Chi-square distribution

The chi-square distribution arises in various contexts, such as the chi-square test for independence.

Let $Z_1, Z_2,..., Z_{\nu}$ be independent random variables that follow the standard normal distribution N(0,1). Then, the sum of the squares of these standard normal random variables, $U=\sum_{i=1}^n Z_i^2$, follows the chi-squared distribution with $\nu$ degrees of freedom, $U \sim\chi_\nu^2$.

Therefore, the chi-squared distribution is determined by a single parameter, $\nu$, which specifies the degrees of freedom (the number of random variables Z being summed). For example, the square of a standard normal variable follows the chi-square distribution with one degree of freedom, $U = Z_{1}^2 \sim \chi_1^2$.

The mean and variance of a random variable that follows the chi-square distribution with $\nu$ degrees of freedom are:

-   $μ = \nu$
-   $σ^2 = 2\nu$

The shape of the chi-square distribution depends on the degrees of freedom, $\nu$.

```{r}
ggplot(data = data.frame(x = c(0, 20)), aes(x = x)) +
  stat_function(fun = function(x) dchisq(x, df = 3), aes(color = "Chi-square (df = 3)"), size = 0.8) +
  stat_function(fun = function(x) dchisq(x, df = 5), aes(color = "Chi-square (df = 5)"), size = 0.8) +
  stat_function(fun = function(x) dchisq(x, df = 9), aes(color = "Chi-square (df = 9)"), size = 0.8) +
  scale_x_continuous(limits = c(0, 20), breaks = seq(0, 20, 1)) +
  scale_color_manual(values = c("purple", "orange", "cyan"),
                     labels = c("ν = 3", "ν = 5", "ν = 9")) +
  labs(x = "Chi-square", y = "Probability Density") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14) +
  theme(legend.title = element_blank())
```

**NOTE:** When $\nu$ is large, the shape of the chi-square distribution becomes increasingly similar to that of a normal distribution.

## 14.4.5 t-distribution

The t-distribution, also known as the Student's t-distribution, is very similar to standard normal distribution and is used in statistics when the sample size is small or when the population standard deviation is unknown.

The Student's t statistic is defined from the formula:

$$ T = \frac{Z}{\sqrt\frac{{U}}{\nu}} $$

where Z∼N(0,1) and U∼$\chi_\nu^2$ are independent.

The t statistic follows the t-distribution with $\nu$ degrees of freedom. As the degrees of freedom increase ($\nu$\> 30), the t-distribution approaches the normal distribution more closely.

The mean and variance of a random variable that follows the t-distribution with $\nu$ degrees of freedom are:

-   $\mu= 0$, $\nu \geq 2$
-   $σ^2 = \nu/(\nu −2)$ , $\nu \geq 3$

The shape of the t-distribution depends on the degrees of freedom, $\nu$

```{r}
ggplot(data = data.frame(x = c(-5, 5)), aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = "a"), size = 0.8) +
  stat_function(fun = function(x) dt(x, df = 3), aes(color = "b = 3"), size = 0.8) +
  stat_function(fun = function(x) dt(x, df = 5), aes(color = "c = 5"), size = 0.8) +
  stat_function(fun = function(x) dt(x, df = 9), aes(color = "d = 9"), size = 0.8) +
  scale_x_continuous(limits = c(-5, 5), breaks = seq(-5, 5, 1)) +
  scale_color_manual(values = c("black", "purple", "orange", "cyan"),
                     labels = c("Standard Normal", "ν = 3", "ν = 5", "ν = 9")) +
  labs(x = "t", y = "Probabiblity Density") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14) +
  theme(legend.title = element_blank())
```

Just like the standard normal distribution, the probability density curve of a t-distribution is bell-shaped and symmetric around its mean (μ = 0). However, the probability density curve of the t-distribution decreases more slowly than that of the standard normal distribution (t-distribution has "heavier" tails than the standard normal distribution).

If the area of the curve is known, it is possible to calculate the corresponding t-value. For example, if each of the shaded light blue areas equal to 0.025, we can find the t-value using the `qt()` function in R:

```{r}
# Create a data frame
df4 <- data.frame(x = seq(-5, 5, by = 0.01),
                  y = dt(seq(-5, 5, by = 0.01), df = 3))

ggplot() +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +
  stat_function(fun = dt, args = list(df = 3), color  = "purple") +
  geom_area(data = df4, mapping = aes(x = ifelse(x < -3, x, -3), y = y), fill = "#0073CF", alpha = 0.3) +  # Area under the curve
  geom_area(data = df4, mapping = aes(x = ifelse(x > 3, x, 3), y = y), fill = "#0073CF", alpha = 0.3) +  # Area under the curve
  scale_x_continuous(limits = c(-5, 5), breaks = seq(-5, 5, 1)) +
  annotate("text", x = 0, y = 0.41, label = "standard normal") +
  annotate("text", x = 0, y = 0.38, label = "t(3)", color = "purple") +
  labs(x = "t", y = "Probabiblity Density") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14)
```

```{r}
qt(0.025, df = 3)
```

```{r}
qt(0.975, df = 3)
```

## 14.4.6 F-distribution

Let U and V be independent random variables that follow the $\chi_{\nu_1}^2$ and $\chi_{\nu_2}^2$, respectively. Then, the random variable:

$$F = \frac{U / \nu_1}{V / \nu_2} $$

follows the F-distribution with $\nu_1$ and $\nu_2$ degrees of freedom, $F \sim F_{\nu_1, \nu_2}$.

The shape of an F-distribution depends on the values of $\nu_1$ and $\nu_2$, the numerator and denominator degrees of freedom, respectively:

```{r}
ggplot(data = data.frame(x = c(0, 5)), aes(x = x)) +
  stat_function(fun = function(x) df(x, df1 = 2, df2 = 1), aes(color = "v1 = 2, v2 = 1"), size = 0.8) +
  stat_function(fun = function(x) df(x, df1 = 3, df2 = 5), aes(color = "v1 = 3, v2 = 5"), size = 0.8) +
  stat_function(fun = function(x) df(x, df1 = 10, df2 = 8), aes(color = "v1 = 10, v2 = 8"), size = 0.8) +
  scale_x_continuous(limits = c(0, 5), breaks = seq(0, 5, 1)) +
  scale_color_manual(values = c("purple", "orange", "cyan"),
                     labels = c("v1 = 2, v2 = 1", "v1 = 3, v2 = 5", "v1 = 10, v2 = 8")) +
  labs(x = "F", y = "Probability Density") +
  scale_y_continuous(expand = c(0,0)) +
  theme_classic(base_size = 14) +
  theme(legend.title = element_blank())
```

The mean and variance of a random variable that follows the F-distribution with $\nu_1$ and $\nu_2$ degrees of freedom are:

-   $\mu = \frac{\nu_2}{\nu_2 - 2}$

-   $\sigma^2 = \frac{2 \nu_2^2 (\nu_1 + \nu_2 - 2)}{\nu_1 (\nu_2 - 2)^2 (\nu_2 - 4)}$
